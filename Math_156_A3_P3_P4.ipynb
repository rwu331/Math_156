{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCAlXJC5/BFsl6I5OytS0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rwu331/Math_156/blob/main/Math_156_A3_P3_P4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Program to train a binary logistic regression model using mini-batch SGD."
      ],
      "metadata": {
        "id": "omFQss_P__U-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def lr_minibatchSGD(X, y, learning_rate=0.01, batch_size=32, max_iter=1000):\n",
        "    def sigmoid(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def cross_entropy_loss(y_true, y_pred):\n",
        "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "    num_samples, num_features = X.shape\n",
        "    w = np.zeros(num_features) # initial weights\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        # shuffle data each time\n",
        "        indices = np.arange(num_samples)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        # mini-batch sgd\n",
        "        for start in range(0, num_samples, batch_size):\n",
        "            batch_indices = indices[start:start + batch_size]\n",
        "            # select the batch\n",
        "            X_batch = X[batch_indices]\n",
        "            y_batch = y[batch_indices]\n",
        "\n",
        "            # predict\n",
        "            linear_model = np.dot(X_batch, w)\n",
        "            y_pred = sigmoid(linear_model)\n",
        "\n",
        "            # calculate gradients\n",
        "            err = y_pred - y_batch\n",
        "            gradient = np.dot(X_batch.T, err) / batch_size\n",
        "\n",
        "            # update weights\n",
        "            w -= learning_rate * gradient\n",
        "\n",
        "    return w\n"
      ],
      "metadata": {
        "id": "_CotwbWAVu_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Run LR model for classification on a breast cancer data set.\n",
        "\n",
        "a). download Wisconsin Breast Cancer dataset"
      ],
      "metadata": {
        "id": "u1AxJ0ogAIA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "N0gC1ZIiAnNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc = load_breast_cancer()"
      ],
      "metadata": {
        "id": "KuAkvjFVANe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b). split the dataset into train, validation, and test sets"
      ],
      "metadata": {
        "id": "51P3SL8jAgbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = bc.data\n",
        "y = bc.target\n",
        "# split data, test-train-val in 75%-15%-10%\n",
        "X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=0.75, random_state=42)\n",
        "x_val, X_test, y_val, y_test = train_test_split(X_other, y_other, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "JsmfYOHyAgJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c). report the size of each class in your training (+ validation) set."
      ],
      "metadata": {
        "id": "xh6yC3TRAu7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count1 = sum(y_train) + sum(y_val)\n",
        "count0 = (y_train.size+y_val.size)-count1\n",
        "print(f\"Class 0: {count0}; Class 1: {count1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KNCKxv-A1W9",
        "outputId": "919dabed-f064-463a-a5f8-441c8fb29ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 191; Class 1: 320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d). train binary LR model"
      ],
      "metadata": {
        "id": "x3BiJYiNA1y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = lr_minibatchSGD(X_train, y_train,learning_rate=0.01, batch_size=10, max_iter=1000)\n",
        "print(\"Trained Weights:\", weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKmvYZkwA7E4",
        "outputId": "474ecc55-a9a3-4226-c983-6332ae3b0906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3989871957a1>:5: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Weights: [ 2.21871603e+01 -1.88603352e+01  7.97604289e+01  4.21492695e+00\n",
            " -1.47805096e-01 -1.60049099e+00 -2.41275463e+00 -9.55374883e-01\n",
            " -2.49776550e-01 -2.02521039e-02  3.12011686e-01  5.59777914e-01\n",
            " -4.82374982e+00 -2.38971891e+01 -3.33956557e-02 -4.35216372e-01\n",
            " -5.67484944e-01 -1.28310058e-01 -9.22341163e-02 -3.83030354e-02\n",
            "  2.29951067e+01 -4.81254250e+01  3.53101443e+01 -1.56258885e+01\n",
            " -4.38248902e-01 -5.46404297e+00 -6.83971581e+00 -1.83039512e+00\n",
            " -1.27069965e+00 -4.09695821e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e). report performance on test set. evaluate use accuracy, precision, recall, and F1-score"
      ],
      "metadata": {
        "id": "oaJoRvJfA7S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def predict(X, w):\n",
        "    probs = sigmoid(np.dot(X, w))\n",
        "    return np.where(probs >= 0.5, 1, 0) # classification using a probability threshold=0.5\n",
        "\n",
        "y_pred_test = predict(X_test, weights)\n",
        "\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUVxl-KjBETg",
        "outputId": "d6780eee-db24-4d7d-c01d-8b66bcc05885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93        21\n",
            "           1       1.00      0.92      0.96        37\n",
            "\n",
            "    accuracy                           0.95        58\n",
            "   macro avg       0.94      0.96      0.95        58\n",
            "weighted avg       0.95      0.95      0.95        58\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-43ec9d437625>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f). summarize findings\n",
        "\n",
        "The model has an overall accuracy of 95% so it correctly classifies 95% of the test samples, which is pretty high. Class 1 has higher precision than class 0 (1>0.88). All class 1 predictions were correct. The recall of class 0 shows that all class 0 cases were correctly identified, no class 0 cases were falsely identified as class 1. The recall of class 1 shows that 92% of the actual class 1 cases are identified, some class 1 cases are missed. The F1-scores of both classes show pretty good balance between precision and recall. Overall, the model performs well."
      ],
      "metadata": {
        "id": "SW1i1rbzBEhC"
      }
    }
  ]
}